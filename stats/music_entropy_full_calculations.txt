====================================================================================================
FULL ENTROPY CALCULATIONS - MATHEMATICAL DETAILS
====================================================================================================
Generated: 2025-10-12 01:49:04
Authors: Sandy H. S. Herho, Rusmawan Suwarman, Edi Riawan, Nurjanna J. Trilaksono
Institution: Weather and Climate Prediction Laboratory (WCPL) ITB
====================================================================================================

BASELINE: ENSO NINO 3.4 INDEX
----------------------------------------------------------------------------------------------------

Shannon Entropy Calculation:
  Number of samples (N):           1860
  Data range:                      [-2.4900, 2.5700]
  Total range:                     5.0600
  Mean:                            -0.0984
  Std. Deviation:                  0.7747
  Interquartile Range (IQR):       0.9900
  Number of bins (Freedman-Diaconis): 32
  Bin width:                       0.158125

  Shannon Entropy H(X):            4.294039 bits
  Maximum Entropy (uniform):       5.000000 bits
  Efficiency (H/H_max):            0.8588

  Formula: H(X) = -∑ p(x_i) × log₂(p(x_i))
  where p(x_i) is the probability density at bin i


Sample Entropy Calculation:
  Embedding dimension (m):         2
  Tolerance (r):                   0.154930
  r as fraction of σ:              0.2000
  Number of samples (N):           1860
  Φ(m):                           66.83593330
  Φ(m+1):                         21.25726588

  Sample Entropy (SampEn):         1.145542

  Formula: SampEn(m,r,N) = -ln[Φ(m+1) / Φ(m)]
  where Φ(m) is the frequency of template matches


====================================================================================================
MODE-BY-MODE ENTROPY CALCULATIONS
====================================================================================================

MODE: PELOG_LAYERED
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 2.506456 bits
   Number of bins used: 27
   Interpretation: On average, each pitch value provides
                   2.5065 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.050799
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.178931
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.132084 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.019552 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 4.546795 bits
   Number of bins used: 28


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.102677 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.1027 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.027495
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 2.75% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.112394 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.102677 / 4.294039 × 100%
                = 2.39%
   Interpretation: This sonification preserves 2.39%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  4.521197 bits
Zero-Crossing Rate Entropy: 4.759187 bits
MI(ENSO, Spectral Centroid): 0.202050 bits

====================================================================================================

MODE: PELOG_ALTERNATING
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 2.188120 bits
   Number of bins used: 18
   Interpretation: On average, each pitch value provides
                   2.1881 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.064893
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.165411
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.320934 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.031026 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 3.910589 bits
   Number of bins used: 19


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.078666 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.0787 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.023956
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 2.40% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.081155 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.078666 / 4.294039 × 100%
                = 1.83%
   Interpretation: This sonification preserves 1.83%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  4.069583 bits
Zero-Crossing Rate Entropy: 4.581363 bits
MI(ENSO, Spectral Centroid): 0.178862 bits

====================================================================================================

MODE: PELOG_MELODIC
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 1.345092 bits
   Number of bins used: 13
   Interpretation: On average, each pitch value provides
                   1.3451 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.065371
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.194377
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.131425 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.013385 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 4.169197 bits
   Number of bins used: 24


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.041947 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.0419 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.014262
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 1.43% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.092810 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.041947 / 4.294039 × 100%
                = 0.98%
   Interpretation: This sonification preserves 0.98%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  4.788401 bits
Zero-Crossing Rate Entropy: 4.764401 bits
MI(ENSO, Spectral Centroid): 0.132605 bits

====================================================================================================

MODE: PELOG_SPECTRAL
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 2.912319 bits
   Number of bins used: 28
   Interpretation: On average, each pitch value provides
                   2.9123 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.075341
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.243590
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.410469 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.024425 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 3.140026 bits
   Number of bins used: 16


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.069400 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.0694 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.018393
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 1.84% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.053694 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.069400 / 4.294039 × 100%
                = 1.62%
   Interpretation: This sonification preserves 1.62%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  5.100268 bits
Zero-Crossing Rate Entropy: 4.083824 bits
MI(ENSO, Spectral Centroid): 0.194552 bits

====================================================================================================

MODE: SLENDRO_LAYERED
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 2.249374 bits
   Number of bins used: 34
   Interpretation: On average, each pitch value provides
                   2.2494 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.018830
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.077979
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.132635 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.020132 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 4.546795 bits
   Number of bins used: 28


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.086292 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.0863 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.023931
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 2.39% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.112394 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.086292 / 4.294039 × 100%
                = 2.01%
   Interpretation: This sonification preserves 2.01%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  4.814260 bits
Zero-Crossing Rate Entropy: 4.560830 bits
MI(ENSO, Spectral Centroid): 0.149824 bits

====================================================================================================

MODE: SLENDRO_ALTERNATING
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 2.199076 bits
   Number of bins used: 23
   Interpretation: On average, each pitch value provides
                   2.1991 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.064504
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.163671
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.322433 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.033185 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 3.910589 bits
   Number of bins used: 19


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.088070 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.0881 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.026776
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 2.68% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.081155 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.088070 / 4.294039 × 100%
                = 2.05%
   Interpretation: This sonification preserves 2.05%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  4.330295 bits
Zero-Crossing Rate Entropy: 4.306798 bits
MI(ENSO, Spectral Centroid): 0.231907 bits

====================================================================================================

MODE: SLENDRO_MELODIC
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 0.850121 bits
   Number of bins used: 13
   Interpretation: On average, each pitch value provides
                   0.8501 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.022902
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.080099
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.132793 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.014677 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 4.169197 bits
   Number of bins used: 24


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.027200 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.0272 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.010097
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 1.01% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.092810 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.027200 / 4.294039 × 100%
                = 0.63%
   Interpretation: This sonification preserves 0.63%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  4.725046 bits
Zero-Crossing Rate Entropy: 4.535525 bits
MI(ENSO, Spectral Centroid): 0.208649 bits

====================================================================================================

MODE: SLENDRO_SPECTRAL
----------------------------------------------------------------------------------------------------

PITCH SEQUENCE ENTROPY ANALYSIS
..................................................

1. Shannon Entropy (Discrete Distribution)
   H(Pitch) = 2.841396 bits
   Number of bins used: 28
   Interpretation: On average, each pitch value provides
                   2.8414 bits of information

2. Sample Entropy (Regularity)
   SampEn(Pitch) = 0.075341
   Interpretation: High regularity (simple)

3. Approximate Entropy (Pattern Complexity)
   ApEn(Pitch) = 0.243590
   Interpretation: Low complexity

4. Permutation Entropy (Ordinal Patterns)
   PE(Pitch) = 0.410469 (normalized, 0-1 scale)
   Interpretation: Highly ordered

5. Spectral Entropy (Frequency Domain)
   SE(Pitch) = 0.023588 (normalized, 0-1 scale)
   Interpretation: Narrow spectrum


VELOCITY SEQUENCE ENTROPY ANALYSIS
..................................................

Shannon Entropy (Discrete Distribution)
   H(Velocity) = 3.140026 bits
   Number of bins used: 16


INFORMATION-THEORETIC COUPLING WITH ENSO
..................................................

Mutual Information Analysis:

1. MI(ENSO, Pitch)
   I(X;Y) = 0.066376 bits
   Formula: I(X;Y) = ∑∑ p(x,y) × log₂[p(x,y)/(p(x)p(y))]
   Interpretation: 0.0664 bits of information are
                   shared between ENSO and pitch sequence

2. Normalized MI(ENSO, Pitch)
   NMI(X;Y) = 0.017758
   Formula: NMI = 2×I(X;Y) / [H(X) + H(Y)]
   Interpretation: 1.78% normalized information overlap

3. MI(ENSO, Velocity)
   I(X;Y) = 0.053694 bits

Information Preservation:
   Preservation = MI(ENSO,Pitch) / H(ENSO) × 100%
                = 0.066376 / 4.294039 × 100%
                = 1.55%
   Interpretation: This sonification preserves 1.55%
                   of the original ENSO signal's information


AUDIO FEATURES ENTROPY (WAV Analysis)
..................................................

Spectral Centroid Entropy:  4.956776 bits
Zero-Crossing Rate Entropy: 3.783911 bits
MI(ENSO, Spectral Centroid): 0.194516 bits

====================================================================================================


GLOSSARY OF ENTROPY MEASURES
====================================================================================================

Shannon Entropy [bits]:
  H(X) = -∑ p(x) log₂(p(x))
  Measures average information content. Higher = more unpredictable.
  Range: 0 to log₂(N) where N is number of unique values.

Sample Entropy [dimensionless]:
  SampEn(m,r,N) = -ln[A/B]
  where A = number of template matches for m+1 points
        B = number of template matches for m points
  Measures regularity. Higher = more complex/irregular.
  Typical range: 0 to 2+

Approximate Entropy [dimensionless]:
  ApEn(m,r,N) = Φ(m) - Φ(m+1)
  Similar to Sample Entropy, measures pattern regularity.
  Higher values = less predictable patterns.

Permutation Entropy [normalized 0-1]:
  PE = H(ordinal patterns) / log₂(m!)
  Based on ordinal patterns in time series.
  0 = completely ordered, 1 = completely random.

Spectral Entropy [normalized 0-1]:
  SE = -∑ p(f) log₂(p(f)) / log₂(N)
  where p(f) is normalized power at frequency f
  Measures frequency distribution. 1 = flat spectrum, 0 = single frequency.

Mutual Information [bits]:
  I(X;Y) = ∑∑ p(x,y) log₂[p(x,y)/(p(x)p(y))]
  Measures statistical dependence between two variables.
  0 = independent, higher = more dependent.

====================================================================================================
END OF ENTROPY CALCULATIONS
====================================================================================================
